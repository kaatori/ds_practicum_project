---
title: "Balanced Data Creation for Clade C vs Non-Clade C & Experimental Logistic Regression for Clade C"
author: "Cassandra Sperow"
date: "2023-11-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Read in Data
```{r}
read_csv("../output/rev_coral_join.csv") -> rev_coral_join
```

## Clade C and Non-Clade C Label Subsetting
```{r}
# Assuming 'df' is your data frame with a column 'labels' and you want to balance the labels

# Extract the minority class samples (139 observations)
minority_class <- rev_coral_join[rev_coral_join$Clade == 'C', ]

# Extract the majority class samples (the rest of the dataset)
majority_class <- rev_coral_join[rev_coral_join$Clade != 'C', ]

# Randomly sample from the majority class to match the size of the minority class
set.seed(42)  # Set a seed for reproducibility
balanced_majority <- majority_class[sample(nrow(majority_class), nrow(minority_class)), ]

# Combine the balanced datasets
balanced_df <- rbind(balanced_majority, minority_class)

# Shuffle the rows to randomize the order
balanced_df <- balanced_df[sample(nrow(balanced_df)), ]

```


```{r}
dim(balanced_df)

unique(balanced_df$Clade)

length(balanced_df$Clade=="C")
length(balanced_df$Clade != "C")

sum(balanced_df$Clade == "D" ) # 2
sum(balanced_df$Clade == "G" ) # 1
```

```{r}
# save the balanced df for later use if needed
write_csv(balanced_df, "../output/balanced_df.csv")
```


## Read in results from PCA Clade C Dim 1 Results
```{r}
read_csv("../output/clade_c_pca_Ranks.csv") -> clade_c_pca_Ranks
```

```{r}
# subset ASV columns for Logistic Regression based on clade C PCA results in Dimension 1
balanced_df %>% 
  select(sample_id, Clade, (clade_c_pca_Ranks$ASV)) -> lr_data
```

```{r}
#glimpse(lr_data)
head(lr_data)
```

```{r}
lr_data %>% 
  mutate(Clade = case_when(Clade=="C" ~ 1, 
                           .default = 0)) -> lr_data
```

### Double-check if any columns sum to 0
```{r}
# take out sample and clade columns for numeric only
map(lr_data[,-c(1,2)], ~sum(.)) %>% 
  as.data.frame() %>% 
  pivot_longer(cols = everything()) %>% 
  filter(value==0)

dim(lr_data)
```
- No columns sum to 0. This had been taken care of when subsetting for Clade C to have ASVs sequenced in Clade C.

- There is sequencing data for Clade C and non-Clade C observations that are all non-zero when summing each ASV column.


```{r}
dim(lr_data)
```

### Inserted this afterwards to be able to work on Random Forest modeling
```{r}
write_csv(lr_data, "../output/lr_data.csv")
```


## Perform recommended data transformation of Centered Log Ratio for bacteria
```{r}
library(compositions)
lr_clr_columns <- clr(lr_data[,-c(1,2)]) %>% 
  as.data.frame()

# scaling the numeric columns to help with warning when running logistic regression
scale(lr_clr_columns) %>% 
  as.data.frame() -> lr_clr_columns

head(lr_clr_columns)

# bind back sample and clade columns
bind_cols(
  lr_data[,c(1,2)], 
  lr_clr_columns
) -> lr_clr_df

head(lr_clr_df)

sum(is.na(lr_clr_df))

map(lr_clr_df, ~sum(is.na(.))) %>% 
  as.data.frame() %>% 
  pivot_longer(cols = everything()) %>% 
  filter(value == NA)
```

```{r}
any(is.na(lr_clr_df))
```


## t-SNE plot of Clade C and non-Clade C
```{r}
library(tsne)
library(plotly)
data(lr_clr_df)

features <- subset(lr_clr_df, select = -c(1,2)) 

set.seed(0)
tsne <- tsne(features, initial_dims = 2)
```
```{r}
tsne <- data.frame(tsne)
pdb <- cbind(tsne,lr_clr_df$Clade)
options(warn = -1)
fig2 <-  plot_ly(data = pdb ,x =  ~X1, y = ~X2, type = 'scatter', mode = 'markers', split = ~lr_clr_df$Clade)

fig2 <- fig2 %>%
  layout(
    plot_bgcolor = "#e5ecf6"
  )

fig2
```
- Data are not linearly separable, but the microbiome community normally does logistic modeling for disease diagnosis. 

- Therefore, will attempt logistic below, but a better technique that would yield some sort of interpretability for classification may be Random Forest.


# GGally::ggpairs for Clade C
```{r}
# quick subset for visualization
subset_lr <- lr_clr_df[,-1] %>% 
  select(1:10)

GGally::ggpairs(subset_lr, aes(color = as.factor(Clade))) -> ggpairs_10_clade_c

ggpairs_10_clade_c

ggsave("../plots/ggpairs_10_clade_c.png", width = 14, height = 12, plot = ggpairs_10_clade_c)

```

## Separate Training and Testing for later after experimenting with whole dataset first
```{r}
set.seed(1234)
Z <- sample(nrow(lr_clr_df), .85*nrow(lr_clr_df))
lr_train <- lr_clr_df[Z,]
lr_test <- lr_clr_df[-Z,]

# take a peek at training data
head(lr_train, 20)
dim(lr_train)
dim(lr_test)
```


### check label distribution of CLade C = 1 and Non-Clade-C = 0
```{r}
ggplot(lr_clr_df, aes( x = Clade)) +
  geom_histogram(stat = 'count') +
  ggtitle("Label Distributions of Clade C = 1 vs. Non-Clade C = 0") +
  theme_bw()
```

# Experiment with whole dataset based on CLR Transformation
## glmnet::glmnet
## 3226
```{r}

y = as.factor(lr_clr_df$Clade)
x = as.matrix(lr_clr_df[,-c(1,2)])

any(is.na(x))

library(glmnet)
lr_model <- glmnet(x, y, 
                 family = "binomial", 
                 #alpha = 1 # lasso L1 norm
                 alpha = 0 # ridge L2 norm
                )
```



```{r}
plot(lr_model)
```
```{r}
summary(lr_model)
lr_model
```

## Cross-Validation
```{r}
cv_results <- cv.glmnet(x, y,
                        family = "binomial",
                        nfolds = 10)
```


```{r}
plot(cv_results)
```


```{r}
cv_results
```


```{r}
summary(lr_model)
```


```{r}
best_lambda <- lr_model$lambda.min

# Refit the model with the selected lambda
best_model <- glmnet(x, y, family = "binomial", alpha = 0, lambda = best_lambda)

coef(best_model)[,1:12]
```



# Stats::glm - Client needs p-values for each bacteria 
# 3226
R documentation: https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/glm

278 x 3226 ASVs
```{r}
library(stats)

logreg <- stats::glm(as.factor(Clade) ~ . ,
                     data = lr_clr_df[,-1],
                     family = "binomial")
```


```{r}
summary(logreg)
```

Recall from Adv ML:
- The n << p here is an underdetermined system. There is not a unique solution. 
- If standard errors of coefficients are very large, which in this case they are, this is not a stable model.

Recall from Regression Classes and Other Course Notes: 
- Null Deviance is for a model with no predictors; just the intercept. 
- Null Deviance measures the goodness of fit of a model with no predictors.
- '$df.null' is the degrees of freedom for the null model: n-1 observations




- Compare the null model with the logreg full model with ~3K predictors
- Null Hypothesis:  Logreg does not provide a significantly better fit for these data
- Alt hypothesis: Logreg provides a much better fit for these data.
```{r}
pchisq(logreg$null.deviance, logreg$df.null, lower.tail = FALSE)
```

- The above statistical test indicates that there is evidence for the alternative hypothesis that the model with predictors is much better than the null model with the intercept. 

```{r}
# Bad fit in notes had a p-value of 0.9995629 from Ressler
# good fit would be the opposite
pchisq(logreg$deviance, logreg$df.residual, lower.tail = FALSE)
```



## 1000 from the PCA results in Dim 1 to see if it helps some of the issues in modeling
### Start with balanced dataset first because will need to be retransformed after first 1000 are subset. 

- They are in order so can simply take first 1000
- Redo transformation based on relative first 1000

```{r}
# lr_clr_df %>%
#   select(1:1002) -> lr_clr_df_1000 # because of id column and response column

lr_data[,1:1002] -> lr_data_1000
 
  
bind_cols(lr_data_1000[,1:2], # sample id and Clade columns
          lr_data_1000[,-c(1,2)] %>% clr() # re-do CLR transformation on relative first 1000 PCA
            ) -> lr_clr_df_1000
  
```

## Logistic with Reduced 1000 ASVs
### glmnet::glmnet
### 1000
### Ridge L2 regularization
## Make sure to re-do with model.matrix
```{r}
# y = as.factor(lr_clr_df_1000$Clade)
# x = as.matrix(lr_clr_df_1000[,-c(1,2)])
# 
# #glimpse(y)
# #dim(x)
# 
# library(glmnet)
# lr_model_1000 <- glmnet(x, y, 
#                         family = "binomial", 
#                         #alpha = 1 ,# lasso L1 norm
#                         alpha = 0 # ridge L2 norm
#                 )


library(glmnet)


# Create a formula for model.matrix
formula <- as.formula(paste("Clade ~ .", sep = "", collapse = ""), env = environment(lr_clr_df_1000))

# Create the design matrix
x_matrix <- model.matrix(formula, data = lr_clr_df_1000[,-1])

# Convert the response variable to a numerical vector
y_vector <- as.numeric(lr_clr_df_1000$Clade) - 1  # glmnet expects 0/1 coding for binary response

# Fit the RIDGE model
RR <- glmnet(x_matrix, 
                      y_vector, 
                      alpha = 0,  # RIDGE
                      family = "binomial")
```


```{r}
RR
summary(RR)
```

```{r}
#plot(RR)
plot(RR, 
     #xlim = c(0, .1), ylim = c(-0.02, 0.02)
     )
```

## Cross-Validation
```{r}
RR_cv_results <- cv.glmnet(x_matrix, 
                        y_vector, 
                        family = "binomial",
                        nfolds = 10)
```


```{r}
plot(RR_cv_results)
```

```{r}
best_RRlambda_1000 <- RR_cv_results$lambda.min

# Refit the model with the selected lambda
best_RRmodel_1000 <- glmnet(x_matrix, y_vector, family = "binomial", 
                            alpha = 0, lambda = best_RRlambda_1000)

coef(best_RRmodel_1000)
```



### stats:glm
### 1000

```{r}
library(stats)

logreg_1000 <- stats::glm(as.factor(Clade) ~ . ,
                          data = lr_clr_df_1000[,-1],
                          family = "binomial")
```


```{r}
summary(logreg_1000)
```

```{r}
pchisq(logreg_1000$null.deviance, logreg_1000$df.null, lower.tail = FALSE)
```

- The above statistical test indicates that there is evidence for the alternative hypothesis that the model with predictors is much better than the null model with the intercept. 

```{r}
# Bad fit in notes example had a p-value of 0.9995629 from Ressler
# good fit would be the opposite
pchisq(logreg_1000$deviance, logreg_1000$df.residual, lower.tail = FALSE)
```

# Using top 500 ASVs to see if the model improves

- They are in order so can simply take first 500, but need to start from counts so that the CLR transformation is relative to the 500 ASVs.

```{r}
# lr_clr_df %>% 
#   select(1:502) -> lr_clr_df_500 # because of id column and response column


lr_data[,1:502] -> lr_data_500
 
  
bind_cols(lr_data_500[,1:2], 
          lr_data_500[,-c(1,2)] %>% clr()
            ) -> lr_clr_df_500

dim(lr_clr_df_500)
head(lr_clr_df_500)
```

## Logistic with Reduced 500 ASVs
### glmnet::glmnet
## re-do with model.matrix
```{r}
y = as.factor(lr_clr_df_500$Clade)
x = as.matrix(lr_clr_df_500[,-c(1,2)])

glimpse(y)
dim(x)

library(glmnet)
lr_model_500 <- glmnet(x, y, 
                        family = "binomial", 
                        #alpha = 1 ,# lasso L1 norm
                        alpha = 0 # ridge L2 norm
                )
```


```{r}
lr_model_500
summary(lr_model_500)
```

```{r}
plot(lr_model_500)
#plot(lr_model_500, xlim = c(0, 50), ylim = c(-0.02, 0.02))
```

## Cross-Validation
```{r}
cv_results_500 <- cv.glmnet(x, y,
                        family = "binomial",
                        nfolds = 10)
```


```{r}
plot(cv_results_500)
```

```{r}
best_lambda_500 <- lr_model_500$lambda.min

# Refit the model with the selected lambda
best_model_500 <- glmnet(x, y, family = "binomial", alpha = 0, lambda = best_lambda_500)

coef(best_model_500)
```





### stats::glm for first 500
```{r}
library(stats)

logreg_500 <- stats::glm(as.factor(Clade) ~ . ,
                          data = lr_clr_df_500[,-1],
                          family = "binomial")
```


```{r}
summary(logreg_500)
```


- The p-values above are all the same which is not good. 


## From PCA of Clade C, there were about 150 or so ASVs that contributed the most in Dimension 1
```{r}
bind_cols(lr_data[,1:2], 
lr_data[3:152] %>% clr() # sample id and Clade
) -> lr_clr_150

logreg_150 <- stats::glm(as.factor(Clade) ~ . ,
                          data = lr_clr_150[,-1],
                          family = "binomial")
```

```{r}
summary(logreg_150)
```


- For these data, it is not possible to get a decent logistic regression model even when reducing the ASV columns to the minimum from PCA analysis. 

- The goal was to try and estimate or explain which ASVs might present the most impact for Clade C, but thes data from the t--SNE plot above and subsequent logistic modeling attempts do not produce a good model. 

- Please see the RandomForest.Rmd file for non-linear modeling. 


# Lasso as ASV Selection
# 1000

LASSO does two things

Shrinks that parameter estimates by penalizing larger slopes -> variance reduction

De-selects variables by setting the slopes to 0 -> dimension reduction.
```{r}
head(lr_clr_df_1000)
```

## model matrix code here

```{r}
library(glmnet)


# Create a formula for model.matrix
formula <- as.formula(paste("Clade ~ .", sep = "", collapse = ""), env = environment(lr_clr_df_1000))

# Create the design matrix
x_matrix <- model.matrix(formula, data = lr_clr_df_1000[,-1])

# Convert the response variable to a numerical vector
y_vector <- as.numeric(lr_clr_df_1000$Clade) - 1  # glmnet expects 0/1 coding for binary response

# Fit the LASSO model
lasso_model <- glmnet(x_matrix, 
                      y_vector, 
                      alpha = 1, 
                      family = "binomial")



```


```{r}
lasso_model

plot(lasso_model, 
     #xlim = c(-0.05, 1)
     )

coef(lasso_model) %>%  # automatically shows 'best' model
  as.matrix() %>% 
  as.data.frame() %>% 
  map(., ~sum(.))
```


- There are many ASVs that have been 'deselected' with a dot ```.```. 
- ASV0013 has coefficients 

```{r}
set.seed(123)
lasso_cv <- cv.glmnet(x_matrix, y_vector)
```

```{r}
lasso_cv
plot(lasso_cv)
```

- There is a difference of 23 variables vs 4 variables for the models with the minimum lambda vs. the lambda within 1 standard deviation. 

- Default 'best' is the lambda within 1 standard deviation of the min lambda. 

- ```lambda.1se``` is the default for the coefficients
```{r}
coef(lasso_cv) %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  filter(s1 != 0)
```

- ```lambda.min``` results
```{r}
coef(lasso_cv, s = "lambda.min") %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  filter(s1 != 0)
```

```{r}

```

# Lasso
# 500

```{r}
# the below was previously subset
# the data transformation was completed on the raw counts after the subset
# to preserve the relativeness of the 500
# is, did not subset after clr because the clr transformation is working off of the relative raw counts.
dim(lr_clr_df_500)
head(lr_clr_df_500)


# Create a formula for model.matrix
formula_500 <- as.formula(paste("Clade ~ .", sep = "", collapse = ""), env = environment(lr_clr_df_500))

# Create the design matrix
x_matrix_500 <- model.matrix(formula, data = lr_clr_df_500[,-1])

# Convert the response variable to a numerical vector
y_vector_500 <- as.numeric(lr_clr_df_500$Clade) - 1  # glmnet expects 0/1 coding for binary response

# Fit the LASSO model
lasso_model_500 <- glmnet(x_matrix_500, # use the reduced 500 ASV df
                      y_vector_500, # reduced y vector of 0-1 response
                      alpha = 1, 
                      family = "binomial")


#lasso_model_500
```


```{r}
plot(lasso_model_500, 
     xlim = c(-0.05, 100), 
     ylim = c(-0.5, 0.5)
     )

coef(lasso_model_500) %>%  # automatically shows 'best' model
  as.matrix() %>% 
  as.data.frame() 
```


```{r}
set.seed(123)
lasso_500_cv <- cv.glmnet(x_matrix_500, y_vector_500)
```

### Lasso Model Resuts for 500 ASVs with Cross-Validation
```{r}

lasso_500_cv


coef(lasso_500_cv) %>% # default is lambda.1se
  as.matrix() %>% 
  as.data.frame() %>% 
  filter(s1 != 0)

coef(lasso_500_cv, s = "lambda.min") %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  filter(s1 != 0)
```


- With lambda.1se, the best model is with 2 ASVs:

ASV0675 and 
ASV0013

- With lambda.min, the best model is with 11 ASVs:

ASV1294		

ASV2062	

ASV0485	

ASV1611	

ASV0675	

ASV0013		

ASV0016		

ASV0446		

ASV0011

```{r}
plot(lasso_500_cv)
```

```{r}

```

