---
title: "Logistic Regression for Clade C"
author: "Cassandra Sperow"
date: "2023-11-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Read in Data
- This 2nd notebook for logistic regression includes the other variables for Species, Region and others to see if it helps stabilize the standard errors of the coefficients. See also 'Logistic Regression Clade C.Rmd'.
```{r}
read_csv("../output/rev_coral_join.csv") -> rev_coral_join
```

## Clade C and Non-Clade C Label Subsetting
```{r}
# Assuming 'df' is your data frame with a column 'labels' and you want to balance the labels

# Extract the minority class samples (139 observations)
minority_class <- rev_coral_join[rev_coral_join$Clade == 'C', ]

# Extract the majority class samples (the rest of the dataset)
majority_class <- rev_coral_join[rev_coral_join$Clade != 'C', ]

# Randomly sample from the majority class to match the size of the minority class
set.seed(42)  # Set a seed for reproducibility
balanced_majority <- majority_class[sample(nrow(majority_class), nrow(minority_class)), ]

# Combine the balanced datasets
balanced_df <- rbind(balanced_majority, minority_class)

# Shuffle the rows to randomize the order
balanced_df <- balanced_df[sample(nrow(balanced_df)), ]

```


```{r}
dim(balanced_df)

unique(balanced_df$Clade)

length(balanced_df$Clade=="C")
length(balanced_df$Clade != "C")
```
## Read in results from PCA Clade C Dim 1 Results
```{r}
read_csv("../output/clade_c_pca_Ranks.csv") -> clade_c_pca_Ranks
```

### Instead of working with only numerical bacterial data, keep in the other columns from joined data.
- Majority is treated the same here as Clade; therefore, it will be removed
- Reef is not unique enough; therefore, remove. 
```{r}
# subset ASV columns for Logistic Regression based on clade C PCA results in Dimension 1
balanced_df %>% 
  select(-Majority, -reef) %>% 
  mutate(ITS2_type = as.factor(ITS2_type)) %>% 
  select(1:6, (clade_c_pca_Ranks$ASV)) %>% 
  mutate(Clade = case_when(Clade=="C" ~ "1", 
                           .default = "0")) -> lr_data_2
```

```{r}
head(lr_data_2)
```



### Double-check if any columns sum to 0
```{r}
# numeric only
map(lr_data_2[,-c(1:6)], ~sum(.)) %>% 
  as.data.frame() %>% 
  pivot_longer(cols = everything()) %>% 
  filter(value==0)

dim(lr_data_2)
```
- No columns sum to 0. This had been taken care of when subsetting for Clade C to have ASVs sequenced in Clade C.

- There is sequencing data for Clade C and non-Clade C observations that are all non-zero when summing each ASV column.


```{r}
dim(lr_data_2)
```


## Perform recommended data transformation of Centered Log Ratio for bacteria
```{r}
library(compositions)
lr_clr_columns_2 <- clr(lr_data_2[,-c(1:6)]) %>% 
  as.data.frame()

# scaling the numeric columns to help with warning when running logistic regression
scale(lr_clr_columns_2) %>% 
  as.data.frame() -> lr_clr_columns_2

#head(lr_clr_columns)

# bind back 
bind_cols(
  lr_data_2[,c(1:6)], # first 6 columns
  lr_clr_columns_2
) -> lr_clr_df_2

#head(lr_clr_df)

sum(is.na(lr_clr_df_2))

map(lr_clr_df_2, ~sum(is.na(.))) %>% 
  as.data.frame() %>% 
  pivot_longer(cols = everything()) %>% 
  filter(is.na(value))
```

```{r}
any(is.na(lr_clr_df_2))
```

# Write balanced dataset to csv 
```{r}
write_csv(lr_clr_df_2, "../output/lr_clr_df_2.csv")
```


# GGally::ggpairs for Clade C
```{r}
# quick subset for visualization
subset_lr_2 <- lr_clr_df_2[,-c(1,3)] %>% # minus sample id and ITS2 type
  select(1:15)

GGally::ggpairs(subset_lr_2, aes(color = as.factor(Clade))) -> ggpairs_15_clade_c

ggpairs_15_clade_c

ggsave("../plots/ggpairs_15_clade_c.png", width = 15, height = 15, plot = ggpairs_15_clade_c)

```

## Separate Training and Testing for later after experimenting with whole dataset first

```{r}
# set.seed(1234)
# Z <- sample(nrow(lr_clr_df), .85*nrow(lr_clr_df))
# lr_train <- lr_clr_df[Z,]
# lr_test <- lr_clr_df[-Z,]
# 
# # take a peek at training data
# head(lr_train, 20)
# dim(lr_train)
# dim(lr_test)
```


### check label distribution of CLade C = 1 and Non-Clade-C = 0
```{r}
ggplot(lr_clr_df_2, aes( x = Clade, color = Clade, fill = Clade)) +
  geom_histogram(stat = 'count') +
  ggtitle("Label Distributions of Clade C = 1 vs. Non-Clade C = 0") +
  theme_bw()
```

# Experiment with whole dataset based on CLR Transformation
## glmnet::glmnet
## 3226
```{r}
dim(lr_clr_df_2)

y = as.factor(lr_clr_df_2$Clade)
x = as.matrix(lr_clr_df_2[,-c(3)]) # minus sample id

any(is.na(x))

library(glmnet)
lr_model <- glmnet(x, y, 
                 family = "binomial", 
                 #alpha = 1 # lasso L1 norm
                 alpha = 0 # ridge L2 norm
                )
```



```{r}
plot(lr_model)
```
```{r}
summary(lr_model)
lr_model
```

## Cross-Validation
```{r}
cv_results <- cv.glmnet(x, y,
                        family = "binomial",
                        nfolds = 10)
```


```{r}
plot(cv_results)
```


```{r}
cv_results
```





```{r}
best_lambda <- lr_model$lambda.min

# Refit the model with the selected lambda
best_model <- glmnet(x, y, family = "binomial", alpha = 0, lambda = best_lambda)

coefficients(best_model)[,1:12]
```



# Stats::glm - Client needs p-values for each bacteria 
# 3226
R documentation: https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/glm

278 x 3226 ASVs
```{r}
library(stats)

logreg <- stats::glm(as.factor(Clade) ~ . ,
                     data = lr_clr_df_2[,-c(1,3)], # minus sample id and ITS2 Type
                     family = "binomial")
```
- Keeping other variables in with such a high factor level of ITS22 Type seems to  have prevented the algorithm from converging. ITS2 Type as a predictor would perfectly seaprate the response variable since the type goes directly into deciding the clade. Remove ITS2 Type and re-run. 

- Same error of not converging and new error of probabilities numerically 0 or 1

```{r}
summary(logreg)
```

- All the p-values are the same - this doesn't seem good. They should be each at least a little different. 

Recall from Adv ML:
- The n << p here is an underdetermined system. There is not a unique solution. 
- If standard errors of coefficients are very large, which in this case they are, this is not a stable model.

Recall from Regression Classes and Other Course Notes: 
- Null Deviance is for a model with no predictors; just the intercept. 
- Null Deviance measures the goodness of fit of a model with no predictors.
- '$df.null' is the degrees of freedom for the null model: n-1 observations




- Compare the null model with the logreg full model with ~3K predictors
- Null Hypothesis:  Logreg does not provide a significantly better fit for these data
- Alt hypothesis: Logreg provides a much better fit for these data.
```{r}
pchisq(logreg$null.deviance, logreg$df.null, lower.tail = FALSE)
```

- The above statistical test indicates that there is evidence for the alternative hypothesis that the model with predictors is much better than the null model with the intercept. 

```{r}
# Bad fit in notes had a p-value of 0.9995629 from Ressler
# good fit would be the opposite
pchisq(logreg$deviance, logreg$df.residual, lower.tail = FALSE)
```


## Need to take the first 1000 from the PCA results in Dim 1 to see if it helps some of the issues in modeling

- They are in order so can simply take first 1000

```{r}
lr_clr_df_2 %>% 
  select(1:1006) -> lr_clr_df_1000 
```

## Logistic with Reduced 1000 ASVs
### glmnet::glmnet
### 1000
### L2 regularization
```{r}
y = as.factor(lr_clr_df_1000$Clade)
x = as.matrix(lr_clr_df_1000[,-c(1,2)])

#glimpse(y)
#dim(x)

library(glmnet)
lr_model_1000 <- glmnet(x, y, 
                        family = "binomial", 
                        #alpha = 1 ,# lasso L1 norm
                        alpha = 0 # ridge L2 norm
                )
```


```{r}
lr_model_1000
summary(lr_model_1000)
```

```{r}
plot(lr_model_1000)
plot(lr_model_1000, xlim = c(0, .1), ylim = c(-0.02, 0.02))
```

## Cross-Validation
```{r}
cv_results <- cv.glmnet(x, y,
                        family = "binomial",
                        nfolds = 10)
```


```{r}
plot(cv_results)
```

```{r}
best_lambda_1000 <- lr_model_1000$lambda.min

# Refit the model with the selected lambda
best_model_1000 <- glmnet(x, y, family = "binomial", alpha = 0, lambda = best_lambda_1000)

coefficients(best_model_1000)[,1:3]
```
```{r}
coef(best_model_1000)
```


### stats:glm
### 1000

```{r}
library(stats)

logreg_1000 <- stats::glm(as.factor(Clade) ~ . ,
                          data = lr_clr_df_1000[,-c(1,3)],
                          family = "binomial")
```


```{r}
summary(logreg_1000)
```

```{r}
pchisq(logreg_1000$null.deviance, logreg_1000$df.null, lower.tail = FALSE)
```

- The above statistical test indicates that there is evidence for the alternative hypothesis that the model with predictors is much better than the null model with the intercept. 

```{r}
# Bad fit in notes example had a p-value of 0.9995629 from Ressler
# good fit would be the opposite
pchisq(logreg_1000$deviance, logreg_1000$df.residual, lower.tail = FALSE)
```

# Using top 500 ASVs to see if the model improves

- They are in order so can simply take first 500

```{r}
lr_clr_df_2 %>% 
  select(1:506) -> lr_clr_df_500 # because of id column and response column

dim(lr_clr_df_500)
```

## Logistic with Reduced 500 ASVs
### glmnet::glmnet

```{r}
y = as.factor(lr_clr_df_500$Clade)
x = as.matrix(lr_clr_df_500[,-c(1,3)])

glimpse(y)
dim(x)

library(glmnet)
lr_model_500 <- glmnet(x, y, 
                        family = "binomial", 
                        #alpha = 1 ,# lasso L1 norm
                        alpha = 0 # ridge L2 norm
                )
```


```{r}
lr_model_500
summary(lr_model_500)
```

```{r}
plot(lr_model_500)
#plot(lr_model_500, xlim = c(0, 50), ylim = c(-0.02, 0.02))
```

## Cross-Validation
```{r}
cv_results_500 <- cv.glmnet(x, y,
                        family = "binomial",
                        nfolds = 10)
```


```{r}
plot(cv_results_500)
```

```{r}
best_lambda_500 <- lr_model_500$lambda.min

# Refit the model with the selected lambda
best_model_500 <- glmnet(x, y, family = "binomial", alpha = 0, lambda = best_lambda_500)

coefficients(best_model_500)
```





### stats::glm for first 500
```{r}
library(stats)

logreg_500 <- stats::glm(as.factor(Clade) ~ . ,
                          data = lr_clr_df_500[,-c(1,3)],
                          family = "binomial")
```


```{r}
summary(logreg_500)
```

```{r}
pchisq(logreg_500$null.deviance, logreg_500$df.null, lower.tail = FALSE)
```

- The above statistical test indicates that there is evidence for the alternative hypothesis that the model with predictors is much better than the null model with the intercept. 

```{r}
# Bad fit in notes example had a p-value of 0.9995629 from Ressler
# good fit would be the opposite
pchisq(logreg_500$deviance, logreg_500$df.residual, lower.tail = FALSE)
```

```{r}

```

