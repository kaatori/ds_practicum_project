---
title: "Ridge & Lasso Modeling of Clade C Bacteria"
author: "Cassandra Sperow"
date: "2023-11-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
suppressMessages(library(tidyverse))
```

# Review Goal & Question(s)
- Can Clade C bacteria be modeled using classification algorithms?
- When Clade C bacteria are modeled, which bacteria strains (ASVs) seem to be the 'best', or most associated, predictors of Clade C?

# Import Logistic Regression Balanced Dataset
- Clade C: n=139
- Non-Clade C: n=139
- Use first 1000 ASVs obtained in PCA Dim.1
- The ```lr_data.csv``` dataset was created by subsetting the Clade C observations from the original 659 samples with random sampling from non-Clade C rows to obtain an equal number of observations for each response label of Clade C = 1, Non-Clade C = 0. This data subsetting process was obtained in the original modeling exploration file 'Logistic Regression Clade C.Rmd'. 
- The Clade C Principal Components Analysis results from dimension 1 were obtained in the file 'PCA-CLR.Rmd'.
- The ASV data are transformed for modeling with the centered log ratio of the raw abundance counts. This is redone when subsetting for the PCA 1000 results and again when subsetting the first 500 PCA results. 

```{r}
# read in balanced Clade C and non-Clade C observations 
read_csv( "../output/lr_data.csv") -> lr_data
# read in saved PCA ranks for Dimension 1
read_csv("../output/clade_c_pca_Ranks.csv") -> clade_c_pca_Ranks
```

```{r}
# order the Clade C ASVs by selecting from the vector of PCA results
lr_data %>% 
  select(sample_id, Clade, (clade_c_pca_Ranks$ASV)) %>% 
  select(1:1002) -> lr_data_1000

dim(lr_data_1000)
```

```{r}
#glimpse(lr_data)
head(lr_data_1000)
```

### Centered-Log-Ratio Data Transformation of 1000 ASV Numeric Columns
```{r}
library(compositions)
# CLR Data Transformation on only ASV numeric columns
bind_cols(lr_data_1000[,1:2], # sample id and Clade columns
          # re-do CLR transformation on relative first 1000 PCA
          lr_data_1000[,-c(1,2)] %>% clr() 
            ) -> lr_clr_df_1000

```

```{r}
head(lr_clr_df_1000)
```

# Training and Testing Split - 85 % Training

```{r}
set.seed(1234)
Z <- sample(nrow(lr_clr_df_1000), .85*nrow(lr_clr_df_1000))
lr_train <- lr_clr_df_1000[Z,]
lr_test <- lr_clr_df_1000[-Z,]

# take a peek at training data
head(lr_train)
dim(lr_train) # 236 x 1002
dim(lr_test) # 42 x 1002
```


# Check Data 
### Class Label Distributions of Training & Testing Data
- Clade C and Non-Clade C histogram

```{r}
ggplot(lr_train, aes( x = Clade, color = as.factor(Clade), fill = as.factor(Clade))) +
  geom_histogram(stat = 'count') +
  ggtitle("Class Label Distributions of Training Data") +
  theme_bw()

ggplot(lr_test, aes( x = Clade, color = as.factor(Clade), fill = as.factor(Clade))) +
  geom_histogram(stat = 'count') +
  ggtitle("Class Label Distributions of Testing Data") +
  theme_bw()
```


# Ridge 1000 

#### Training

- ```glmnet``` documentation:

https://glmnet.stanford.edu/articles/glmnet.html

```{r}
library(glmnet)
# create model matrix for glmnet
#stats::model.matrix()

# Create a formula for model.matrix
formula <- as.formula(paste("Clade ~ .", sep = "", collapse = ""), 
                      env = environment(lr_train))

# Create the design matrix
# take out the sample id
x_train <- stats::model.matrix(formula, data = lr_train[,-c(1)])
dim(x_train)

# Convert the response variable to a numerical vector
# glmnet expects 0/1 coding for binary response
y_train <- lr_train$Clade  
length(y_train)


# Train the RIDGE model
RR <- glmnet(x_train[,-1], # take out intercept
             y_train, 
             alpha = 0,  # RIDGE
             family = "binomial")
```

### RR Plot
```{r}
base::plot(RR, 
     ylim = c(-0.5, 0.5),
     label = TRUE
     )
```

#### Training Cross-Validation
```{r}
set.seed(123)
rr_cv <- cv.glmnet(x_train[,-1], 
                   y_train, 
                   alpha = 0, # Ridge
                   type.measure = "class", # must have for classification
                   family = "binomial" # classification
                   )
rr_cv
```

- From CV results, the standard error for the lambda.min is smaller than for lambda.1se. 
- The error rate is lower for the lambda.min at 33.9 %


```{r}
base::plot(rr_cv) 
```



#### Best Ridge Model 1000 from Training & Cross-Validation
```{r}

# Refit the model with the selected lambda
best_RR_1000 <- glmnet(x_train[,-1], # take out intercept bc it will fit another one
                       y_train, 
                       family = "binomial", 
                       alpha = 0, # Ridge
                       lambda = rr_cv$lambda.min )

#coef(best_RR_1000) %>% as.matrix()
#best_RR_1000


```

#### Ridge Testing 1000
```{r}

dim(lr_test) # 42 x 1002

x_test <- stats::model.matrix(formula,
                              data = lr_test[,-c(1)]
                              )
y_test <- lr_test$Clade
```


```{r}
predict(best_RR_1000, 
        newx =  x_test[,-1], # take out intercept bc it will fit a new one
        type = "class", # must have for misclass rate
        s = "lambda.min" # min from training cross-validation
          ) -> yhat

```


```{r}
# error rate
mean((as.numeric(yhat) - y_test)^2) -> ridge_1000_error
ridge_1000_error

# confusion matrix
table(yhat, y_test) 

# correct classification rate
paste("Correct Classification Rate: ", round((13 + 16)/42, 2  ))# 42 testing rows

# Error Rate
#paste("Error Rate: ", round( (13/42), 3))
paste("Error rate: ", round(ridge_1000_error, 2))

```
- Testing Error Rate for the ridge model with 1000 ASVs is 16.7 %.  
- Correct Classification Rate: 83.3 %
- This model predicted that 7 rows are Clade C when they were not in the testing data. 


# Ridge 500 
### Data Prep
- Subset from original counts for the first 500 ASVs from PCA results
```{r}
# subset the first 500 
lr_data_1000[, 1:502] -> lr_data_500

# redo CLR transformation with counts for first 500
bind_cols(lr_data_500[,1:2], 
          lr_data_500[,-c(1,2)] %>% clr() 
            ) -> lr_clr_500
```

```{r}
set.seed(1234)
Z <- sample(nrow(lr_clr_500), .85*nrow(lr_clr_500))
lr_train_500 <- lr_clr_500[Z,]
lr_test_500 <- lr_clr_500[-Z,]

# take a peek at training data
head(lr_train_500)
dim(lr_train_500) # 236 x 502
dim(lr_test_500) # 42 x 502

# Create a formula for model.matrix using the 500 dataframe
formula <- as.formula(paste("Clade ~ .", sep = "", collapse = ""), 
                      env = environment(lr_train_500))

# Create the design matrix
# take out the sample id
x_train_500 <- stats::model.matrix(formula, data = lr_train_500[,-c(1)])
dim(x_train_500) # 501 because there's an intercept

# Convert the response variable to a numerical vector
# glmnet expects 0/1 coding for binary response
y_train_500 <- lr_train_500$Clade  
length(y_train_500)
typeof(y_train_500) # glmnet expects numeric even for classificiation
```


#### Training 500
```{r}
# Train the RIDGE model with 500 ASVs
RR_500 <- glmnet(x = x_train_500[,-1], # take out intercept
                 y = y_train_500, 
                 alpha = 0,  # RIDGE
                 family = "binomial") # do not need type = class here

base::plot(RR_500)
```

#### Cross-Validation
```{r}
set.seed(1234)
rr_500_cv <- cv.glmnet(x = x_train_500[,-1], # take out intercept
                       y = y_train_500, 
                       family = "binomial", 
                       type.measure = "class")

rr_500_cv
```

```{r}
base::plot(rr_500_cv)
```

### Ridge 500 Best Model & Refit
```{r}
# Refit the model with the selected lambda
best_RR_500 <- glmnet(x = x_train_500[,-1], # take out intercept
                      y = y_train_500, 
                      family = "binomial", 
                      alpha = 0, # Ridge
                      lambda = rr_500_cv$lambda.min )

best_RR_500
```

### Ridge 500 Testing
```{r}
dim(lr_test_500) # 42 x 502

x_test_500 <- stats::model.matrix(formula,
                              data = lr_test_500[,-c(1)]
                              )
y_test_500 <- lr_test_500$Clade

predict(best_RR_500, 
        newx =  x_test_500[,-1], # take out intercept bc it will fit a new one
        type = "class", # must have for misclass rate
        s = "lambda.min" # min from training cross-validation
          ) -> yhat_500


```


```{r}
mean((as.numeric(yhat_500) - y_test_500)^2) -> ridge_500_error
paste("Error rate: ", round(ridge_500_error, 2))

paste("Confusion Matrix: ")
table(yhat_500, y_test_500)

paste("Correct Classification Rate: ", 
round(((15 + 15)/ 42), 2)
)
```

- Error rate for using 500 ASVs is 28.6 %
- Correct Classification Rate is 71.4 %


# Lasso 1000
- Using same 1000 column dataframe as Ridge 1000 section above
```{r}
dim(x_train) # includes intercept
length(y_train) # 139 clade C = 1, 139 not clade C = 0

# Train the LASSO model
lasso <- glmnet(x_train[,-1], # take out intercept
             y_train, 
             alpha = 1,  # Lasso
             family = "binomial")


base::plot(lasso, 
     xlim = c(0, 5),
     ylim = c(-0.2, 0.2)
     )
```

### Lasso CV
```{r}
set.seed(123)
lasso_cv <- cv.glmnet(x_train[,-1], 
                   y_train, 
                   alpha = 1, # Lasso
                   type.measure = "class", # must have for classification
                   family = "binomial" # classification
                   )
lasso_cv

base::plot(lasso_cv)
```

- lambda.min has a lower error rate of 36.4 %
- lambda.min has 73 Non-Zero Coefficients out of 1000 ASVs


```{r}
# Refit the model with the selected lambda
best_lasso_1000 <- glmnet(x_train[,-1], # take out intercept bc it will fit another one
                       y_train, 
                       family = "binomial", 
                       alpha = 1, # Lasso
                       lambda = lasso_cv$lambda.min )

#best_lasso_1000
```

### Lasso Testing 1000


```{r}
dim(x_test) # includes intercept

dim(lr_test) # 42 x 1002

x_test <- stats::model.matrix(formula,
                              data = lr_test[,-c(1)]
                              )
y_test <- lr_test$Clade
length(y_test)

predict(best_lasso_1000, 
        newx =  x_test[,-1], # take out intercept bc it will fit a new one
        type = "class", # must have for misclass rate
        s = "lambda.min" # min from training cross-validation
          ) -> yhat

```
```{r}
mean((as.numeric(yhat) - y_test) ^2) -> lasso_1000_error
paste("Error rate: ", lasso_1000_error)

paste("Confusion Matrix: ")
table(yhat, y_test)

paste("Correct Classification Rate: ",  
      round((14+11)/42, 2)
      )
```

- Testing error rate for lasso model with 1000 ASVs is 40.5 %
- Correct classification rate is about 60 %


# Lasso 500
- Use previously created 500 dataframe with it's above CLR transformation
```{r}
# Create a formula for model.matrix using 500
formula <- as.formula(paste("Clade ~ .", sep = "", collapse = ""), 
                      env = environment(lr_train_500))

# Create the design matrix
# take out the sample id
x_train_500 <- stats::model.matrix(formula, data = lr_train_500[,-c(1)])
dim(x_train_500)


# glmnet expects 0/1 coding for binary response
y_train_500 <- lr_train_500$Clade  
length(y_train_500)
typeof(y_train_500)

# checking training data 
dim(x_train_500)


# Train the LASSO model with 500 ASVs
lasso_500 <- glmnet(x = x_train_500[,-1], # take out intercept
                 y = y_train_500, 
                 alpha = 1,  # Lasso
                 family = "binomial") # do not need type = class here

base::plot(lasso_500)
```


#### Cross-Validation

```{r}
set.seed(1234)
lasso_500_cv <- cv.glmnet(x = x_train_500[,-1], # take out intercept
                       y = y_train_500, 
                       family = "binomial", 
                       type.measure = "class")

lasso_500_cv
```

- lambda.min has the lower misclassification rate in training of 34.3 %

```{r}
base::plot(lasso_500_cv)
```

#### Best Lasso Model from Training & Cross-Validation

```{r}
# Refit the model with the selected lambda
best_lasso_500 <- glmnet(x = x_train_500[,-1], # take out intercept
                      y = y_train_500, 
                      family = "binomial", 
                      alpha = 1, # Lasso
                      lambda = lasso_500_cv$lambda.min )

best_lasso_500
```

#### Lasso Testing 500
```{r}
dim(lr_test_500) # 42 x 502

x_test_500 <- stats::model.matrix(formula,
                              data = lr_test_500[,-c(1)]
                              )
y_test_500 <- lr_test_500$Clade

predict(best_lasso_500, 
        newx =  x_test_500[,-1], # take out intercept bc it will fit a new one
        type = "class", # must have for misclass rate
        s = "lambda.min" # min from training cross-validation
          ) -> yhat_500

```

```{r}
paste("Error rate: ")
mean((as.numeric(yhat_500) - y_test_500)^2) -> lasso_500_error
round(lasso_500_error, 2)

paste("Confustion Matrix: ")
table(yhat_500, y_test_500)

paste("Correct Classification Rate: ")
round((11 + 16)/ 42, 2)
```

- Testing Error rate for the lasso model with 500 ASVs is 35.7 %.

- Testing Correct Classification rate is 64.3 %

# Overall Error Rates
```{r}
data.frame( 
  model = c("ridge_1000_error", 
  "ridge_500_error",
  "lasso_1000_error",
  "lasso_500_error"), 
  error_rates = c(
    ridge_1000_error, 
  ridge_500_error,
  lasso_1000_error,
  lasso_500_error)
  ) %>% 
  arrange(error_rates)
```

- The ridge classificiation model with 500 ASVs has the lowest error rate at 28.6 %. 
- Correct Classification Rate: 71.4 %

- The lasso classification model with 500 ASVs has the lower of the two lasso models at 35.7 %. 
- Correct Classification Rate of the Lower Lasso Model: 64.3 %. 

# ASV Coefficients by Best Ridge Model for Clade C Prediction
```{r}
# coef(best_RR_1000, s = "lambda.min") %>% 
#   as.matrix() %>% 
#   as.data.frame() %>% 
#   filter(s1 != 0) %>% 
#   mutate(abs_coef = abs(s1)) %>% 
#   arrange(-abs_coef)

coef(best_RR_500, s = "lambda.min") %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  filter(s1 != 0) %>% 
  mutate(abs_coef = abs(s1)) %>% 
  arrange(-abs_coef)
```


# ASVs Selected by Best Lasso Model for Clade C Prediction

```{r}
# coef(best_lasso_1000, s = "lambda.min") %>% 
#   as.matrix() %>% 
#   as.data.frame() %>% 
#   filter(s1 != 0) %>% 
#   mutate(abs_coef = abs(s1)) %>% 
#   arrange(-abs_coef)

coef(best_lasso_500, s = "lambda.min") %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  filter(s1 != 0) %>% 
  mutate(abs_coef = abs(s1)) %>% 
  arrange(-abs_coef)
```

- The best lasso method with 500 possible ASV predictors selected the above ASVs as the 'best' predictors. 
